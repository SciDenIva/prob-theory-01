**Теорема**

Пусть $\eta_n = \xi_1 + \cdots + \xi_n$, где $\xi$ - независимы в совокупности и 
$$
\xi_i = 
\Bigg\{
\begin{array}{rl}
+1, & p = 1/2 \\        
-1, & p = 1/2 \\        
\end{array}
$$

То $\forall a > 0, P(\eta_n \ge a) \le e ^{-a^2/2n}$

$\square$

Возьмем $\lambda > 0$,

$$
P(\eta_n \ge a) = P(\lambda\cdot\eta_n \ge \lambda\cdot a) = \\
\ \\
\ возьмем\ exp\ от\ каждой\ части\\
\ \\
= P(e^{\displaystyle\lambda\cdot\eta_n} \ge e^{\displaystyle\lambda\cdot a}) \le
\ \\
\ применим\ неравенство\ Маркова,\ т.к.\ exp\ от\ случайной\ величины\\
это\ неотрицательно\ значная\ величина \\
\ \\
\le \frac{E(e^{\displaystyle\lambda\cdot\eta_n})}{e^{\displaystyle\lambda\cdot a}} = e^{\displaystyle-\lambda\cdot a}\cdot\prod\limits_{i=1}^n E(e^{\displaystyle\lambda\cdot\eta_n}) = \\
\ \\
e^{\displaystyle-\lambda\cdot a}\cdot \Big( \frac{1}{2}\cdot e^{\displaystyle\lambda\cdot 1} + \frac{1}{2}\cdot e^{\displaystyle\lambda\cdot (-1)} \Big)^n = e^{\displaystyle-\lambda\cdot a}\cdot \Big( \frac{e^{\displaystyle\lambda} + e^{\displaystyle-\lambda}}{2} \Big)^n = \\
\ \\
разложим\ в\ ряд\ Тейлора\\
\ \\
= e^{\displaystyle-\lambda a} \Big( \sum\limits_{k=0}^{\infty} \frac{\lambda^{2k}}{(2k)!} \Big)^n \le \\
\ \\
т.к.\ (2k)! \ge (k!)\cdot 2^n\\
\ \\
\le e^{\displaystyle-\lambda a} \Big( \sum\limits_{k=0}^{\infty} \frac{\lambda^{2k}}{k!\cdot 2^k} \Big)^n = e^{\displaystyle-\lambda a} \Bigg( \sum\limits_{k=0}^{\infty} \frac{1}{k!}\Big(\frac{\lambda^{2}}{2}\Big)^k \Bigg)^n = \\
\ \\
= e^{\displaystyle-\lambda a} \cdot e^{\displaystyle\frac{\lambda^2}{2} n} = e^{\displaystyle-\lambda a + \frac{\lambda^2}{2} n} = \\
\ \\
в\ качестве\ \lambda\ выберем\ \lambda = \frac{a}{n} \\
\ \\
= e^{-a^2/2n}
$$

$\blacksquare$

**Теорема** ЗБЧ (Закон Больших Чисел) в форме Чебышёва

Пусть $\xi_1, \ldots, \xi_n, \ldots$ - последовательность случайных величин, которые одинаково распределены, т.е. у них одинаковое $E\xi = E{\xi_1}$, имеют конечный $2$-ой момент, т.е. $E\xi^2 < \infty$ и $\xi_i$ попарно не коррелированны.

Тогда $\forall\ \varepsilon > 0, P\Big(\displaystyle \Big\vert \frac{\xi_1 + \cdots + \xi_n}{n} - E\xi_1\Big\vert \ge \varepsilon\Big)\rightarrow 0$, при $n\rightarrow \infty$.

Теорема описывает близость среднеарифметического значения эксперимента и математического ожидания.

$\square$

$\displaystyle P\Big( \Big\vert \frac{\xi_1 + \cdots + \xi_n}{n} - E\xi_1 \Big\vert \ge \varepsilon \Big) \ge \frac{D_{\eta_n}}{\varepsilon^2}$, где $\displaystyle\eta_n = \frac{\xi_1 + \cdots + \xi_n}{n}$, а $E\xi_1$ является $\displaystyle E \frac{\xi_1 + \cdots + \xi_n}{n}$, т.к. $\displaystyle\frac{1}{n} \Big( E\xi_1 + \cdots + E\xi_n \Big) = \frac{n}{n} = E\xi_1$, т.е. $\displaystyle E\xi_1 = E\Big(\frac{\xi_1 + \cdots + \xi_n}{n}\Big)$

$$
P\Big( \Big\vert \frac{\xi_1 + \cdots + \xi_n}{n} - E\xi_1 \Big\vert \ge \varepsilon \Big) \ge \frac{D_{\eta_n}}{\varepsilon^2} = \\
\ \\
из\ под\ дисперсии\ константа\ выносится\ с\ квадратом \\
\ \\
= \frac{1}{n^2 \varepsilon^2}\cdot \Big( D\xi_1 + \cdots + D\xi_n \Big) = \frac{1}{n^2 \varepsilon^2}\cdot n D\xi_1 =\frac{D\xi_1}{n\varepsilon^2}
$$
при фиксированном $\varepsilon > 0$ и $n\to\infty$.

Можно модифицировать утверждение на случай, когда случайные величины не одинаково распределены.

**Теорема**

Пусть $\xi_1, \ldots, \xi_n, \ldots$ - последовательность попарно не коррелируемых случайных величин, у которых распределения разные, но такие, что существует $c: \forall\ i\ D\xi_i \le c$, т.е. существует общая константа, которая ограничивает дисперсии всех этих случайных величин.

Тогда $\forall\ \varepsilon > 0$

$$
P\Bigg( \Bigg\vert \frac{\xi_1 + \cdots + \xi_n}{n} - E\Big( \frac{\xi_1 + \cdots + \xi_n}{n} \Big) \Bigg\vert \ge \varepsilon \Bigg) \rightarrow 0, n\to\infty
$$

Доказательство точно такое же кроме того, что $(D\xi_1 + \cdots + D\xi_n) \le nC$

> ЗБЧ можно получить и без условия существования дисперсий, но тогда нужна будет независимость в совокупности, а не коррелированность как сейчас.

Пусть $\xi\thicksim Poisson(\lambda)$, $\displaystyle P(\xi = k) = \frac{\lambda^k \cdot e^{-\lambda}}{k!}$

Факториальный момент $E_f^r \xi = E\big( \xi(\xi-1)\times \cdot \times (\xi - r + 1)\big) = \lambda^r$

$X_3(G)$ - число треугольников в $G$.

Обычно $E$ находится исходя из знаний о распределении, но иногда не зная ничего о распределениее можно подстчитать математическое ожидание.

## Формула обращения и пуассоновская апроксимация

Находим распределение исходя из моментов, а не наоборот.

**Теорема**

Пусть $\xi:\Omega\rightarrow \{0, 1, 2, \ldots, n\}$, тогда

$$
P(\xi = k) = \sum\limits_{r=k}^n (-1)^{r-k} \cdot \frac{E_f^r \xi}{k! (r-k)!},
$$
т.е. распределение случайной величины $\xi$ выражаем через факториальные моменты. Формула напоминает формулы включения/исключения.

$\square$

Введем индикатор 
$$
I_{\{\xi = k\}} (w) = \Bigg\{
\begin{array}{rl}
1,& если\ \xi = k \\
0,& иначе
\end{array}
$$

$I$ - это случайная величина и индикатор события, что $\xi = k$.

$$
E(I_{\{\xi = k\}}) = P(\xi = k)
$$

Нам достаточно доказать, что
$$
I_{\{\xi=k\}}=\sum\limits_{r=k}^n (-1)^{r-k}\cdot \frac{\xi(\xi-1)\times \cdots \times (\xi-r+1)}{k! (r-k)!},
$$
так если от обоих частей взять математическое ожидание, то мы получим искомую формулу.

Пусть $\xi = l$. Рассмотрим три случая: $l < k$, $l = k$, $l > k$.

1) $l < k$

Из этого следует, что $I_{\{\xi = k\}} = 0$, т.е. слева $0$, а справа 

$$
\sum\limits_{r=k}^n (-1)^{r-k}\cdot \frac{\xi(\xi-1)\times \cdots \times (\xi-r+1)}{k! (r-k)!}
$$

Подставим $\xi = l$

$$
\sum\limits_{r=k}^n (-1)^{r-k}\cdot \frac{l(l-1)\times \cdots \times (l-r+1)}{k! (r-k)!}
$$

Если $r=k$, то имеем $l(l-1)\times \cdots \times (l-k+1) =(l-0)(l-1)\times \cdots \times (l-(k-1))$, но т.к. $l<k$, то одно из вычитаемых будет $l$, так как вычитаемые $0,1,2,\ldots, k-1$, т.е. один из сомножителей будет $0$, и следовательно, все слагаемые равны $0$.

Теперь рассмотрим случай, когда $r = k + 1$. Имеем $(l-0)(l-1)\times \cdots \times (l-(k - 1 + 1))$, т.е. число слагаемых увиличилось, и следовательно, мы гарантировано будем иметь предыдущую ситуацию с $0$.

Таким образом, для случая $l < k$  формула верна.

2. $l = k$

Имеем $I_{\{\xi = k\}} = 1$.

При $r = k$ получаем

$$
(-1)^0\cdot \frac{(k-0)(k-1)\times \cdots \times (k-k+1)}{k! 0!} = (-1)^0 \cdot \frac{k!}{k! 0!} = 1
$$

При $r = k + 1$ получаем $(k-0)(k-1)\times \cdots \times (k-k)$, т.е. добавляем $0$-ой сомножитель и далее сомножители будут только добавляться.

Т.е. при $l = k$ только одно слагаемой даст $1$, а все остальные будут равны $0$.

Таким образом, для случая $l = k$  формула верна.

3. $l > k$

Имеем $I_{\{\xi = k\}} = 0$.

Если $l = k$ (предыдущий случай), то только одно слагаемое не обнулится

$$
\sum\limits_{r=k}^n (-1)^{r-k}\cdot \frac{l(l-1)\times \cdots \times (l-r+1)}{k! (r-k)!} = \\
\ \\
ненулевые\ будут\ только\ до\ l \\
\ \\
= \sum\limits_{r=k}^l (-1)^{r-k}\cdot \frac{l(l-1)\times \cdots \times (l-r+1)}{k! (r-k)!} = \\
\ \\
заменим\ r-k\ на\ m \\
\ \\
= \sum\limits_{m = 0}^{l - k} (-1)^m\cdot \frac{l(l-1)\times \cdots \times (l-m -k +1)}{k! m!}
$$

> Бином Ньютона для $(1 - 1)^a = C_a^0 - C_a^1 + \cdots + (-1)^a C_a^a = 0$ для $a > 0$. Если в этой формуле $a = 0$, то $(1-1)^0 = 1$ и это соответствует случаю 2.

Нам нужно свести все к 
$$
\sum\limits_{m=0}^{l-k} (-1)^m C_{l-k}^m = 0
$$

$$
C_{l-k}^m = \frac{(l-k)!}{m!(l-k)}=\frac{(l-k)(l-k+1)\times \cdots \times (l-k-m+1)}{m!}
$$

Подставляем
$$
\sum\limits_{m = 0}^{l - k} (-1)^m\cdot \frac{l(l-1)\times \cdots \times (l-m -k +1)}{k! m!} = \\
\ \\
= \frac{1}{k!}\sum\limits_{m = 0}^{l - k} (-1)^m\cdot \frac{l(l-1)\times \cdots \times (l-m -k +1)}{m!} = \\
\ \\
= \frac{1}{k!}\sum\limits_{m = 0}^{l - k} l(l-1)\times \cdots \times (l-k+1) \cdot (-1)^m C_{l-k}^m = \\
\ \\
= \frac{l(l-1)\times \cdots \times (l-k+1)}{k!}\sum\limits_{m = 0}^{l - k} (-1)^m C_{l-k}^m = 0
$$

$\blacksquare$

**Следствие из формулы обращения**

Пусть есть последовательность случайных величин $\xi_1, \ldots, \xi_n, \ldots$, которые принимают не отрицательные целые значения.

Пусть существует $\lambda > 0 : \forall\ r\ E_f^r \xi_n \xrightarrow[n\to\infty]{} \lambda^r$. 

Тогда
$$
\forall\ k\ P(\xi_n = k)\xrightarrow[n\to\infty]{} \frac{\lambda^k e^{-\lambda}}{k!},
$$
т.е. если есть случайные величины, у которых факториальные моменты похожи на пуассоновские, то они и распределены также, как и пуассоновские.

Это теорема Пуассона в пределе.

Это следствие называется Пуассоновской аппроктимацией.

Мы знаем, что 
$$
P(\xi_n = k) = \sum\limits_{r=k}^\infty (-1)^{r-k}\frac{\lambda^r(1 + o(1))}{k! (r-k)!} \thicksim \sum\limits_{r=k}^\infty \frac{\lambda^r(-1)^{r-k}}{k! (r-k)!}
$$ 

Подставим $m = r - k$.
$$
P(\xi_n = k) = \sum\limits_{m = 0}^\infty \frac{\lambda^{m + k}(-1)^m}{k! m!} = \\
\ \\
= \frac{\lambda^k}{k!} \sum\limits_{m = 0}^\infty \frac{(-1)^m}{m!} \lambda^m = \\
\ \\
это\ ряд\ Тейлора\ для\ e^{-\lambda} \\
\ \\
= \frac{\lambda^k e^{-\lambda}}{k!}
$$ 



## Условная вероятность

$A, B \subset \Omega$ - события и $P(B) \neq 0$.

$P(A\mid B)$ - условная вероятность события $A$ если произошло событие $B$.

$$
P(A\mid B) = \frac{P(A \cap B)}{P(B)}
$$

### Пример

Бросили кубили и выпало $P(w_6)$. Исход не оглашают, но говорят, что выпало четное число.

$A=\{w_6\}$, $B=\{w_2, w_4, w_6\}$

Т.к. $B$ уже произошло, то смотрим на пересечение $A \cap B$.

$$
\frac{\mid A \cap B \mid}{\mid B \mid} = \frac{\mid A \cap B \mid}{\mid B \mid}\frac{/ \ \mid \Omega \mid}{/ \ \mid \Omega \mid} = \frac{P(A \cap B)}{P(B)}
$$

Можно переписать
$$
P(A \cap B) = P(A \mid B)\cdot P(B)
$$

Это называется _теоремой умножения_ (название сложилось исторически).

## Независимость событий

$A$ и $B$ - _независимые_ события, если $P(A \cap B) = P(A)\cdot P(B)$

Независимость - это не тоже самое, что и _несовместность_.

$A$ независит от $B$, если $P(A \mid B) = P(A)$

Независимость - симметричное утверждение, т.е. $P(B \mid A) = P(B)$

Домножим первое равенство на $P(B)$, а второе на $P(A)$. Получим
$$
P(A \mid B)\cdot P(B) = P(A)\cdot P(B) \\
P(B \mid A)\cdot P(A) = P(B)\cdot P(A) \\
$$

Слева получаем $P(A\cap B)$. Таким образом
$$
P(A\cap B) = P(A)\cdot P(B) = P(B)\cdot P(A)
$$

Пусть есть события $A_1, \ldots , A_n$.

Можно говорить о попарной независимости, как выше, а можно о независимости _в совокупности_ или _взаимно независимости_.

Если взять любой набор событий и рассматривать их пересечение, то вероятность пересечения будет равна произведению вероятностей.

Для любого $I \subseteq \{ 1,2,\ldots , n\}$ - подмножество индексов.

$$
P\Big(\bigcap _{i\in I} A_i\Big) = \prod\limits_{i \in I} P(A_i)
$$

Может достаточно попарной независимости, чтобы независимость в совокупности выполнялась?

**Пример #1** Покрашенный тетраэдр

Грани тетраэдра покрашены цветами: красный, желтый, зеленый и полосатый (красным, желтым и зеленым).

События $R, Y, G$ состоят в том, что после подбрасывания тетраэдр встанет на грань с красным, желтым или зеленым цветом соответственно.

$$
P(R) = P(Y) = P(G) = \frac{1}{2}
$$

$$
P(R \cap Y) = P(R \cap G) = P(Y \cap G) = \frac{1}{4}
$$

Т.е. имеет место попарная независимость, но

$$
P(R \cap Y \cap G) = \frac{1}{4} \neq \frac{1}{8}
$$

**Пример #2** Геометрический

<img src='img/prob-2.svg'>

Рассмотрим три события, когда случайно выбранная точка оказывается в одной из трех областей:

- Вертикальный левый прямоугольник - $AC$ 
- Горизонтальный нижний прямоугольник - $CD$
- Диагональ - $AD$

При этом
- Вероятность каждого из событий - $\displaystyle \frac{1}{2}$
- Попарная вероятность - $\displaystyle \frac{1}{4}$
- Совместная вероятность  - $0$

**Пример #3** Раскраска чисел

Есть множество чисел $\{1,2,3,4,5,6\} = R$.

Рассмотрим случайную раскраску этих чисел в два цвета, т.е. каждому числу ставим в соответствие один из цветов.

Всего существует $2^n$ раскрасок, т.е. $\mid \Omega \mid = 2^n$.

$\Omega = \{\chi_1, \chi_2, \ldots, \chi_{64}\}$.

Рассмотрим два множества $A,B \subset R$ и соответствующие им события $\cal A, B$.

Событие $\cal A$ состоит в том, что случайная раскраска будет такая, что все числа из $A$ окажутся одного цвета. То же для $\cal B$ и $B$.

Как взаимное расположение изначально зафиксированных множеств $A$ и $B$ влияет на зависимость/независимость событий $\cal A$ и $\cal B$.

Интуитивно понятно, что $A \cap B = \oslash \iff \cal A$ и $\cal B$ - независимы.

Если $\mid A \cap B \mid = 1$, то $\cal A$ и $\cal B$ также независимы.

Но если $\mid A \cap B \mid > 1$, то $\cal A$ и $\cal B$ становятся зависимыми.

## Формала полной вероятности

Поделим $\Omega$ на непересекающиеся области $B_1, B_2, \ldots, B_n$, такие что $P(B_i) \neq 0$.

Рассмотрим событие $A \subset \Omega$.
$$
P(A) = \sum\limits_{i=1}^n P(A \cap B_i)
$$

Применим теорему умножения.

$$
P(A) = \sum\limits_{i=1}^n P(A \cap B_i) = \sum\limits_{i=1}^n P(A \mid B_i)\cdot P(B_i)
$$

**Пример** Урновые вероятности

В первой урне $2$ белых и $1$ черный шар. Во второй урне $3$ белых и $1$ черный шар.
Из первой урны во вторую наугад переложили $1$ шар, а затем из второй урны вынули $2$ шара.

Какова вероятность, что эти $2$ шара будут белыми? Это событие $A$.

Такде имеем следующие события:

- $B_1$ - из первой урны вытащили черный шар
- $B_2$ - из первой урны вытащили белый шар

Тогда 

$$
P(A) = P(A\mid B_1)\cdot P(B_1) + P(A\mid B_2)\cdot P(B_2) = \frac{1}{2}
$$

Так как $\displaystyle P(B_1) = \frac{1}{3}$, $\displaystyle P(B_2) = \frac{2}{3}$, $\displaystyle P(A\mid B_1) = \frac{3}{10}$, $\displaystyle P(A\mid B_2) = \frac{6}{10}$.

## Формула Байеса

Имеем $P(A\cap B)=P(A\mid B)\cdot P(B)=P(B\mid A)\cdot P(A)$.

Тогда, перенося множители и применяя формулу полной вероятности
$$
P(B_i\mid A) = \frac{P(A\mid B_i)\cdot P(B_i)}{P(A)} = \frac{P(A\mid B_i)\cdot P(B_i)}{\sum\limits_{j=1}^n P(A\mid B_j)\cdot P(B_j)}
$$

**Пример** Тестовое задание

Есть тестовое задание, в котором из $k$ вариантов ответов нужно выбрать только один правильный. Известно, что если студент умеет решать подобные задачи, то он точно выберет правильный ответ. Если же он не знает, то он выбирает ответ наугад, т.е. он выберет правильный ответ с вероятностью $\displaystyle \frac{1}{k}$.

Преподаватель проверяет задание и видит, что оно сделано правильно. При этом по опыту он знает, что в среднем студент знает, как решить задачу с вероятностью $p \in [0, 1]$.

Преподаватель хочет знать, с какой вероятностью данный конкретный студент умеет решать такие задачи?

Имеем события

- $A$ - ответ верный
- $B_1$ - студент умеет решать задачу
- $B_2$ - студент НЕ умеет решать задачу

$$
P(B_1 \mid A) = \frac{P(A\mid B_1)\cdot P(B_1)}{P(A\mid B_1)\cdot P(B_1) + P(A\mid B_2)\cdot P(B_2)} = \frac{1 \cdot p}{1 \cdot p + \displaystyle\frac{1}{k}\cdot (1-p)}
$$

## Схема испытаний Бернулли

Подбрасывает монету

- $p\in [0,1]$ - вероятность "решки"
- $1-p = q \in [0,1]$ - вероятность "орла"

$n$-раз бросаем монету

$w$ - элементарный исход последовательности наблюдений бросания монеты

$w = (x_1, \ldots, x_n)$, где 
- $x_i = 0$ - если выпал "орел" (неудача)
- $x_i = 1$ - если выпала "решка" (успех)

Все наблюдения взаимно независимы.

$\mid \Omega \mid = 2^n$ 

$$
P(w) = p^{x_1}\cdot q^{1-x_1}\cdot p^{x_2}\cdot q^{1-x_2}\cdot\ldots \cdot p^{x_n}\cdot q^{1-x_n} = p^{\  \sum\limits_{i=1}^n x_i}\cdot q^{\ n- \sum\limits_{i=1}^n x_i}
$$

Рассмотрим событие $A\subseteq \Omega$, что после $n$ бросаний $k$ раз выпадет "решка" (1).

$$
P(A) = C_n^k \cdot p^k \cdot q^{n-k}
$$




